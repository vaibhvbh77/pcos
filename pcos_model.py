# -*- coding: utf-8 -*-
"""PCOS_Analysis_Model (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mlPd8XGC3xqZru9ZZ61zIqh91K6PLstr
"""

import pandas as pd

import numpy as np

df=pd.read_csv("PCOS ANALYSIS FINAL.csv")

df.columns

df.columns=['time','diagnosed','result','age','overweight','weightgain','periods','conceiving','chinHair','cheeksHair','upperLipHair','betweenBreastHair','armsHair','innerThighHair','acneOrskinTag','hairThinning','darkPatch','tiredness','moodSwings','exercise','eatOutside','cannedFood','city']

new=pd.DataFrame(df[df.diagnosed=='Yes'])

new

new.reset_index(drop=True,inplace=True)
new

new.drop('time',axis=1,inplace=True)
new

import numpy as np

new.weightgain.fillna('abc',inplace=True)

y=pd.DataFrame(new.result)

y.head()

new.drop('result',axis=1,inplace=True)
new

def g(s):
    if(s=="YES"):
        return 1
    if(s=="NO"):
        return 0
    if s=="Yes":
        return 1
    if s=="No":
        return 0
    if s=="abc":
        return 2

new["Diagnose"]=new.diagnosed.apply(g)
new["Overweight"]=new.overweight.apply(g)
new["Weightgain"]=new.weightgain.apply(g)
new["Periods"]=new.periods.apply(g)
new["Conceiving"]=new.conceiving.apply(g)
new["AcneOrskinTag"]=new.acneOrskinTag.apply(g)
new["HairThinning"]=new.hairThinning.apply(g)
new["DarkPatch"]=new.darkPatch.apply(g)
new["Tiredness"]=new.tiredness.apply(g)
new["MoodSwings"]=new.moodSwings.apply(g)
new["CannedFood"]=new.cannedFood.apply(g)
new["City"]=new.city.apply(g)
del new["diagnosed"]
del new["overweight"]
del new["weightgain"]
del new["periods"]
del new["conceiving"]
del new["acneOrskinTag"]
del new["hairThinning"]
del new["darkPatch"]
del new["tiredness"]
del new["moodSwings"]
del new["cannedFood"]
del new["city"]
new.head()

new.dtypes

new[:][1:2]

new.isnull().sum()

def f(s):
    if(s=="Yes"):
        return True
    if(s=="No"):
        return False
    if(s=="Yes(Detected Positive)"):
        return True
    if(s=="No(Detected Negative)"):
        return False
y=y.result.apply(f)

y.head()

#converting dataframe to array
xnew=new.values
ynew=y.values

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler(copy=True)
scaler.fit(xnew)
x_scaled=scaler.transform(xnew)

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(xnew,ynew,random_state=3)

from sklearn.metrics import classification_report,confusion_matrix

from sklearn.svm import SVC
clf=SVC(kernel='poly',degree=2,C=0.01)
clf.fit(x_train,y_train)
ypredsvm=clf.predict(x_test)
clf.score(x_train,y_train),clf.score(x_test,y_test)

from sklearn.tree import DecisionTreeClassifier
clf1=DecisionTreeClassifier()
clf1.fit(x_train,y_train)
ypredDT=clf1.predict(x_test)
clf1.score(x_train,y_train),clf1.score(x_test,y_test)

new.columns

clf1.feature_importances_

from sklearn.naive_bayes import GaussianNB
clf2=GaussianNB()
clf2.fit(x_train,y_train)
ypredNB=clf2.predict(x_test)
clf2.score(x_train,y_train),clf2.score(x_test,y_test)

from sklearn.linear_model import LinearRegression
clf5=LinearRegression()
clf5.fit(x_train,y_train)
ypredLR=clf5.predict(x_test)
clf5.score(x_train,y_train),clf5.score(x_test,y_test)

from sklearn.linear_model import LogisticRegression
clf3 = LogisticRegression(C=0.01)
clf3.fit(x_train,y_train)
ypredLR=clf3.predict(x_test)
clf3.score(x_train,y_train),clf3.score(x_test,y_test)

from sklearn.neighbors import KNeighborsClassifier
clf6=KNeighborsClassifier(n_neighbors=3)
clf6.fit(x_train,y_train)
ypredKNN=clf6.predict(x_test)
clf6.score(x_train,y_train),clf6.score(x_test,y_test)

from sklearn.ensemble import RandomForestClassifier
clf7 = RandomForestClassifier(criterion="entropy")
clf7.fit(x_train, y_train)
ypredRF=clf7.predict(x_test)
clf7.score(x_train,y_train),clf7.score(x_test,y_test)

from sklearn.model_selection import StratifiedKFold

def Stacking(model,train,y,test,n_fold):
    folds=StratifiedKFold(n_splits=n_fold,random_state=1)
    test_pred=np.empty((test.shape[0],1),float)
    train_pred=np.empty((0,1),float)
    for train_indices,val_indices in folds.split(train,y.values):
        x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]
        y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]

        model.fit(X=x_train,y=y_train)
        train_pred=np.append(train_pred,model.predict(x_val))
        test_pred=np.append(test_pred,model.predict(test))
    return test_pred.reshape(-1,1),train_pred

xtrain=pd.DataFrame(x_train)
ytrain=pd.DataFrame(y_train)
xtest=pd.DataFrame(x_test)
test_pred1 ,train_pred1=Stacking(model=clf6,n_fold=5, train=xtrain,test=xtest,y=ytrain)
test_pred2 ,train_pred2=Stacking(model=clf1,n_fold=5, train=xtrain,test=xtest,y=ytrain)
test_pred3 ,train_pred3=Stacking(model=clf,n_fold=5, train=xtrain,test=xtest,y=ytrain)

train_pred1=pd.DataFrame(train_pred1)
test_pred1=pd.DataFrame(test_pred1)

train_pred2=pd.DataFrame(train_pred2)
test_pred2=pd.DataFrame(test_pred2)

train_pred3=pd.DataFrame(train_pred3)
test_pred3=pd.DataFrame(test_pred3)

test_pred1=test_pred1.iloc[:41]
test_pred2=test_pred2.iloc[:41]
test_pred3=test_pred3.iloc[:41]

df_train = pd.concat([train_pred1, train_pred2, train_pred3], axis=1)
df_test = pd.concat([test_pred1, test_pred2,test_pred3], axis=1)

ytest=pd.DataFrame(y_test)
model = RandomForestClassifier(random_state=1,criterion="entropy")
model.fit(df_train,y_train)
model.score(df_test,y_test)

#Bagging 
from sklearn. ensemble import BaggingClassifier, AdaBoostClassifier, VotingClassifier
bg = BaggingClassifier(clf3, max_samples= 0.5, max_features = 1.0, n_estimators = 20)
bg.fit(x_train,y_train)
bg.score(x_test,y_test)

#Boosting - Ada Boost
adb = AdaBoostClassifier(LogisticRegression(),n_estimators = 5, learning_rate = 1)
adb.fit(x_train,y_train)
adb.score(x_test,y_test)

evc = VotingClassifier( estimators= [('svm',clf),('dt',clf1),('nb',clf2),('lr',clf3),('knn',clf6)], voting = 'hard')
evc.fit(x_train,y_train)
evc.score(x_test, y_test)

from sklearn.cluster import KMeans
from sklearn.metrics import mean_squared_error
kmeans=KMeans(n_clusters=2
             )

ypredKn=[]
kmeans.fit(x_train)
for i in kmeans.labels_:
    ypredKn.append(int(not i))
rmse=mean_squared_error(ypredKn,y_train)
rmse

from sklearn.model_selection import cross_val_score
x_axis=[]
y_axis=[]
for i in range(1,14):
    clf=KNeighborsClassifier(n_neighbors=i)
    score=cross_val_score(clf,x_test,y_test)
    x_axis.append(i)
    y_axis.append(score.mean())
    print(i,score.mean())

print(cross_val_score(clf,x_test,y_test))
print(cross_val_score(clf1,x_test,y_test))
print(cross_val_score(clf2,x_test,y_test))
print(cross_val_score(clf3,x_test,y_test))

# import pydotplus
# from sklearn.tree import export_graphviz
# dot_data = export_graphviz(clf1, out_file=None,
#                           feature_names=new.columns,
#                           class_names=['yes','no'])
# graph = pydotplus.graph_from_dot_data(dot_data)
# graph.write_pdf("pcos4_entropy1.pdfpdf")

df2=pd.read_csv("https://raw.githubusercontent.com/PCOS-Survey/PCOSData/master/PCOS-Data.csv",delimiter=",")
df2

len(df2.columns)

df2.columns=['patient','periods','weightgain','hair','patches','pimples','depression','familyDiabetes','mantainingBodyweight','oilyskin','hairThinning','eat','exercise','sleepAfter','wakeUp','hostel','personalProblems','peerPressure','dietrtyHabits','eatFastFoods','result']

df2.head()

df2.drop('patient',axis=1,inplace=True)
df2.head()

df2.describe()

df2.isnull().sum()

df2.dropna(inplace=True)

df2.describe()

df2.head()

df2.periods.unique()

df2.eatFastFoods.unique()

df2.hostel.unique()

def func(s):
    if s=='y':
        return 1
    if s=='n':
        return 0
    if s=='no':
        return 0
    if s=='No':
        return 0
    if s=='yes':
        return 1
    if s=='hm':
        return 1
    if s=='cc':
        return 0
    if s=='e':
        return 1
    if s=='ed':
        return 1
    if s=='w':
        return 2
    if s=='m':
        return 3
    if s=='y':
        return 4

def time(s):
    return(str(s[0:2]))

df2["newSleepAfter"]=df2.sleepAfter.apply(time)

df2.head()

df2["newWakeUp"]=df2.wakeUp.apply(time)
df2.head()

df2["Weightgain"]=df2.weightgain.apply(func)
df2["Hair"]=df2.hair.apply(func)
df2["Patches"]=df2.patches.apply(func)
df2["Pimples"]=df2.pimples.apply(func)
df2["Depression"]=df2.depression.apply(func)
df2["FamilyDiabetes"]=df2.familyDiabetes.apply(func)
df2["MaintainingBodyWeight"]=df2.mantainingBodyweight.apply(func)
df2["OilySkin"]=df2.oilyskin.apply(func)
df2["Hairthinning"]=df2.hairThinning.apply(func)
df2["Hostel"]=df2.hostel.apply(func)
df2["PersonalProblems"]=df2.personalProblems.apply(func)
df2["PeerPressure"]=df2.peerPressure.apply(func)
df2["DietryHabits"]=df2.dietrtyHabits.apply(func)
df2["EatFastFoods"]=df2.eatFastFoods.apply(func)

df2.head()

df2.columns

del df2['weightgain']
del df2['hair']
del df2['patches']
del df2['pimples']
del df2['depression']
del df2['familyDiabetes']
del df2['mantainingBodyweight']
del df2['oilyskin']
del df2['hairThinning']
del df2['eat']
del df2['exercise']
del df2['sleepAfter']
del df2['wakeUp']
del df2['hostel']
del df2['personalProblems']
del df2['peerPressure']
del df2['dietrtyHabits']
del df2['eatFastFoods']

def res(s):
    if s=='mb n' or s==' mb n':
        return False
    if s=='mb':
        return True
df2['Result']=df2.result.apply(res)
df2.head()

del df2["result"]
df2.head()

df2.periods.unique()

def periods(s):
    if s=='No':
        return 0
    if s=='yes':
        return 1
    if s=='hb':
        return 2
    if s=='im' or s=='Im':
        return 3
    if s=='ib':
        return 4
df2["Periods"]=df2.periods.apply(periods)
del df2["periods"]
df2.head()

df2.newWakeUp.unique()

df2.newSleepAfter.unique()

def news(s):
    if str(s)=='1:':
        return '1'
    if str(s)=='3:':
        return '3'
    if str(s)=='7:':
        return '7'
    if str(s)=='8:':
        return '8'
    if str(s)=='6:':
        return '6'
    if str(s)=='9:':
        return '9'
    else:
        return s

df2["WakeUp"]=df2.newWakeUp.apply(news)

df2["SleepAfter"]=df2.newSleepAfter.apply(news)

del df2["newSleepAfter"]
del df2["newWakeUp"]

df2.head()

y=df2.Result.values
y

del df2["Result"]

x=df2.values
x

x_train2,x_test2,y_train2,y_test2=train_test_split(x,y,random_state=3)

from sklearn.svm import SVC
clf=SVC(kernel='linear',C=100000)
clf.fit(x_train2,y_train2)
clf.score(x_train2,y_train2),clf.score(x_test2,y_test2)

from sklearn.tree import DecisionTreeClassifier
clf1=DecisionTreeClassifier(random_state=4)
clf1.fit(x_train2,y_train2)
clf1.score(x_train2,y_train2),clf1.score(x_test2,y_test2)

from sklearn.naive_bayes import GaussianNB
clf2=GaussianNB()
clf2.fit(x_train2,y_train2)
clf2.score(x_train2,y_train2),clf2.score(x_test2,y_test2)

from sklearn.linear_model import LinearRegression
clf5=LinearRegression()
clf5.fit(x_train2,y_train2)
clf5.score(x_train2,y_train2),clf5.score(x_test2,y_test2)

# from sklearn.linear_model import LogisticRegression
# clf3 = LogisticRegression(C=5000,random_state=5)
# clf3.fit(x_train2,y_train2)
# clf3.score(x_train2,y_train2)
# clf3.score(x_test2,y_test2)

from sklearn.neighbors import KNeighborsClassifier
clf6=KNeighborsClassifier(n_neighbors=1)
clf6.fit(x_train2,y_train2)
clf6.score(x_train2,y_train2),clf6.score(x_test2,y_test2)

xtrain2=pd.DataFrame(x_train2)
ytrain2=pd.DataFrame(y_train2)
xtest2=pd.DataFrame(x_test2)
test_pred11 ,train_pred11=Stacking(model=clf1,n_fold=10, train=xtrain2,test=xtest2,y=ytrain2)
test_pred22 ,train_pred22=Stacking(model=clf6,n_fold=10, train=xtrain2,test=xtest2,y=ytrain2)

train_pred11=pd.DataFrame(train_pred11)
test_pred11=pd.DataFrame(test_pred11)

train_pred22=pd.DataFrame(train_pred22)
test_pred22=pd.DataFrame(test_pred22)

test_pred11=test_pred11.iloc[:29]
test_pred22=test_pred22.iloc[:29]

df_train = pd.concat([train_pred11, train_pred22], axis=1)
df_test = pd.concat([test_pred11, test_pred22], axis=1)

ytest=pd.DataFrame(y_test2)
model = LogisticRegression(random_state=1)
model.fit(df_train,y_train2)
model.score(df_test,y_test2)

#Bagging 
# from sklearn. ensemble import BaggingClassifier, AdaBoostClassifier, VotingClassifier
# bg = BaggingClassifier(clf3, max_samples= 0.5, max_features = 1.0, n_estimators = 20)
# bg.fit(x_train,y_train)
# bg.score(x_test,y_test)

#Boosting - Ada Boost
adb = AdaBoostClassifier(LogisticRegression(),n_estimators = 5, learning_rate = 0.001)
adb.fit(x_train2,y_train2)
adb.score(x_test2,y_test2)

# evc = VotingClassifier( estimators= [('svm',clf),('dt',clf1),('nb',clf2),('lr',clf3),('knn',clf6)], voting = 'hard')
# evc.fit(x_train2,y_train2)
# evc.score(x_test2, y_test2)

from sklearn.model_selection import cross_val_score
x_axis=[]
y_axis=[]
for i in range(1,14):
    clf=KNeighborsClassifier(n_neighbors=i)
    score=cross_val_score(clf,x_test2,y_test2)
    x_axis.append(i)
    y_axis.append(score.mean())
    print(i,score.mean())

